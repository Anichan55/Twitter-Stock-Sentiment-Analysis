pip install flair

import numpy as np
import matplotlib.pyplot as plt

import string
import re
import requests
import os
import textwrap

from datetime import datetime, timedelta
import pandas as pd

bearer_token='AAAAAAAAAAAAAAAAAAAAAIRUSQEAAAAAWLbfpT20bMYhL2hRtEq3aEXHefU%3DjI5tBIHPozlQZZ4WNskkSU9BBawkyOlrNT6hr9KCdspbhoui0n'
def bearer_oauth(r):
    """
    Method required by bearer token authentication.
    """

    r.headers["Authorization"] = f"Bearer {bearer_token}"
    r.headers["User-Agent"] = "v2RecentSearchPython"
    return r

    params = {
    'tweet_mode': 'extended',
    'lang': 'en',
    'count': '100'
}



def get_data(tweet):
    data = {
        'id': tweet['id_str'],
        'created_at': tweet['created_at'],
        'text': tweet['full_text']
    }
    return data

dtformat = '%Y-%m-%dT%H:%M:%SZ'  # the date format string required by twitter

# we use this function to subtract 60 mins from our datetime string
def time_travel(now, mins):
    now = datetime.strptime(now, dtformat)
    back_in_time = now - timedelta(minutes=mins)
    return back_in_time.strftime(dtformat)
    
now = datetime.now()  # get the current datetime, this is our starting point
last_week = now - timedelta(days=7)  # datetime one week ago = the finish line
now = now.strftime(dtformat)  # convert now datetime to format for API

df = pd.DataFrame()  # initialize dataframe to store tweets
while True:
    if datetime.strptime(now, dtformat) < last_week:
        # if we have reached 7 days ago, break the loop
        break
    pre60 = time_travel(now, 60)  # get 60 minutes before 'now'
    # assign from and to datetime parameters for the API
    response = requests.get('https://api.twitter.com/1.1/search/tweets.json?q=birla', auth=bearer_oauth,params = {'tweet_mode': 'extended','lang': 'en','count': '100','start_time':pre60,'end_time':now})  # send the request
    now = pre60  # move the window 60 minutes earlier
    # iteratively append our tweet data to our dataframe
    for tweet in response.json()['statuses']:
      row = get_data(tweet)
      df = df.append(row, ignore_index=True)

tweets=df
tweets['sentiment'] = np.nan
tweets['probability']=np.nan
len(tweets)

import flair
sentiment_model = flair.models.TextClassifier.load('en-sentiment')

i=0
for t in tweets['text']:
  whitespace = re.compile(r"\s+")
  web_address = re.compile(r"(?i)http(s):\/\/[a-z0-9.~_\-\/]+")
  user = re.compile(r"(?i)@[a-z0-9_]+")
  RT=re.compile(r"RT :")
# we then use the sub method to replace anything matching
  tweet = whitespace.sub(' ', t)
  tweet = web_address.sub('', tweet)
  tweet = user.sub('', tweet)
  tweet = RT.sub('',tweet)
  tweets['text'][i]=tweet
  i=i+1

for i in range(0,len(tweets)):
  sentence = flair.data.Sentence(tweets['text'][i])
  sentiment_model.predict(sentence)
  probability = sentence.labels[0].score  # numerical value 0-1
  sentiment = sentence.labels[0].value  # 'POSITIVE' or 'NEGATIVE'
  tweets['sentiment'][i]=sentiment
  tweets['probability'][i]=probability
  
tweets

avg_positive_sentiment=sum(tweets['probability'][tweets['sentiment']=='POSITIVE'])/sum(tweets['sentiment']=='POSITIVE')
avg_negative_sentiment=sum(tweets['probability'][tweets['sentiment']=='NEGATIVE'])/sum(tweets['sentiment']=='NEGATIVE')
total_positive_sentiment=sum(tweets['probability'][tweets['sentiment']=='POSITIVE'])
total_negative_sentiment=sum(tweets['probability'][tweets['sentiment']=='NEGATIVE'])

(total_positive_sentiment - total_negative_sentiment)
